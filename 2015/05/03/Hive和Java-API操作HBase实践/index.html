<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Hive和Java API操作HBase实践 · Snow Memory | Andrew Liu</title><meta name="description" content="Hive和Java API操作HBase实践 - Andrew Liu"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://andrewliu.in/atom.xml" title="Snow Memory | Andrew Liu"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/dinosaurliu" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/Andrew-liu" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Hive和Java API操作HBase实践</h1><div class="post-info">May 3, 2015</div><div class="post-content"><p>本博客采用创作共用版权协议, 要求署名、非商业用途和保持一致. 转载本博客文章必须也遵循<a href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh" target="_blank" rel="external">署名-非商业用途-保持一致</a>的创作共用协议.</p>
<blockquote>
<p>由于五一假期, 成文较为简略, 一些细节部分并没有详细介绍, 如有需求, 可以参考之前几篇相当MapRuduce主题的博文.</p>
</blockquote>
<h1 id="HBase实践"><a href="#HBase实践" class="headerlink" title="HBase实践"></a>HBase实践</h1><ul>
<li>修改MapReduce阶段倒排索引的信息通过文件输出, 而每个词极其对应的<code>平均出现次数</code>信息写入到Hbase的表<code>Wuxia</code>中(具体的要求可以查看之前的博文<a href="http://andrewliu.tk/2015/04/18/MapReduce%E4%B9%8B%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/#4-_MapReduce实战之倒排索引" target="_blank" rel="external">MapReduce实战之倒排索引</a>)</li>
<li>编写Java程序, 遍历上一步保存在HBase中的表, 并把表格的内容保存到本地文件中.</li>
<li>Hive使用Hive Shell命令行创建表(<code>表名:</code> Wuxia, (word string, count double)), 导入平均出现次数的数据<ul>
<li>查询出现次数大于300的词语</li>
<li>查询前100个出现次数最多的数</li>
</ul>
</li>
</ul>
<a id="more"></a>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</div><div class="line"><span class="keyword">import</span> java.util.StringTokenizer;</div><div class="line"><span class="keyword">import</span> java.util.Iterator;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.*;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer.Context;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HColumnDescriptor;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HTableDescriptor;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HBaseAdmin;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableReducer;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableOutputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.TableReducer;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.*;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InvertedIndexHbase</span> </span>&#123;</div><div class="line">    <span class="comment">//创建表并进行简单配置</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createHBaseTable</span><span class="params">(Configuration conf, String tablename)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line"><span class="comment">//      HBaseConfiguration configuration = new HBaseConfiguration();</span></div><div class="line">        HBaseAdmin admin = <span class="keyword">new</span> HBaseAdmin(conf);</div><div class="line">        <span class="keyword">if</span> (admin.tableExists(tablename)) &#123;  <span class="comment">//如果表已经存在</span></div><div class="line">            System.out.println(<span class="string">"table exits, Trying recreate table!"</span>);</div><div class="line">            admin.disableTable(tablename);</div><div class="line">            admin.deleteTable(tablename);</div><div class="line">        &#125;</div><div class="line">        HTableDescriptor htd = <span class="keyword">new</span> HTableDescriptor(tablename); <span class="comment">//row</span></div><div class="line">        HColumnDescriptor col = <span class="keyword">new</span> HColumnDescriptor(<span class="string">"content"</span>); <span class="comment">//列族</span></div><div class="line">        htd.addFamily(col); <span class="comment">//创建列族</span></div><div class="line">        System.out.println(<span class="string">"Create new table: "</span> + tablename);</div><div class="line">        admin.createTable(htd); <span class="comment">//创建表</span></div><div class="line">    &#125;</div><div class="line">    <span class="comment">//map函数不变</span></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> </span></div><div class="line">    <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; &#123;</div><div class="line">        <span class="keyword">private</span> Text keyWord = <span class="keyword">new</span> Text();</div><div class="line">        <span class="keyword">private</span> Text valueDocCount = <span class="keyword">new</span> Text();</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span></span></div><div class="line">        <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">            <span class="comment">//获取文档</span></div><div class="line">            FileSplit fileSplit = (FileSplit)context.getInputSplit();</div><div class="line">            String fileName = fileSplit.getPath().getName();</div><div class="line">            StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</div><div class="line">            <span class="keyword">while</span>(itr.hasMoreTokens()) &#123;</div><div class="line">                keyWord.set(itr.nextToken() + <span class="string">":"</span> + fileName);  <span class="comment">// key为key#doc</span></div><div class="line">                valueDocCount.set(<span class="string">"1"</span>); <span class="comment">// value为词频</span></div><div class="line">                context.write(keyWord, valueDocCount);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//combine函数不变</span></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">InvertedIndexCombiner</span></span></div><div class="line">        <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; &#123;</div><div class="line">        <span class="keyword">private</span> Text wordCount = <span class="keyword">new</span> Text();</div><div class="line">        <span class="keyword">private</span> Text wordDoc = <span class="keyword">new</span> Text();</div><div class="line">        <span class="comment">//将key-value转换为word-doc:词频</span></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, </span></span></div><div class="line">                Context context) <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">            <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">            <span class="keyword">for</span> (Text value : values) &#123;</div><div class="line">                sum += Integer.parseInt(value.toString());</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">int</span> splitIndex = key.toString().indexOf(<span class="string">":"</span>);  <span class="comment">// 找到:的位置</span></div><div class="line">            wordDoc.set(key.toString().substring(<span class="number">0</span>, splitIndex));  <span class="comment">//key变为单词</span></div><div class="line">            wordCount.set(sum + <span class="string">""</span>);  <span class="comment">//value变为doc:词频</span></div><div class="line">            context.write(wordDoc, wordCount);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//reduce将数据存入HBase</span></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span></span></div><div class="line">        <span class="keyword">extends</span> <span class="title">TableReducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>&gt; &#123;</div><div class="line">        <span class="keyword">private</span> Text temp = <span class="keyword">new</span> Text();</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, </span></span></div><div class="line">                Context context) <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">            <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">            <span class="keyword">int</span> count = <span class="number">0</span>;</div><div class="line">            Iterator&lt;Text&gt; it = values.iterator();</div><div class="line">            <span class="comment">//形成最终value</span></div><div class="line">            <span class="keyword">for</span>(;it.hasNext();) &#123; </div><div class="line">                count++;</div><div class="line">                temp.set(it.next());</div><div class="line">                sum += Integer.parseInt(temp.toString());</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">float</span> averageCount = (<span class="keyword">float</span>)sum / (<span class="keyword">float</span>)count;</div><div class="line">            FloatWritable average = <span class="keyword">new</span> FloatWritable(averageCount);</div><div class="line">            <span class="comment">//加入row为key.toString()</span></div><div class="line">            Put put = <span class="keyword">new</span> Put(Bytes.toBytes(key.toString()));  <span class="comment">//Put实例, 每一词存一行</span></div><div class="line">            <span class="comment">//列族为content, 列修饰符为average表示平均出现次数, 列值为平均出现次数</span></div><div class="line">            put.add(Bytes.toBytes(<span class="string">"content"</span>), Bytes.toBytes(<span class="string">"average"</span>), Bytes.toBytes(average.toString()));</div><div class="line">            context.write(NullWritable.get(), put); </div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        String tablename = <span class="string">"Wuxia"</span>;</div><div class="line">        Configuration conf = HBaseConfiguration.create();</div><div class="line">        conf.set(TableOutputFormat.OUTPUT_TABLE, tablename);</div><div class="line">        createHBaseTable(conf, tablename);</div><div class="line">        Job job = Job.getInstance(conf, <span class="string">"Wuxia"</span>);  <span class="comment">//配置作业名</span></div><div class="line">        <span class="comment">//配置作业的各个类</span></div><div class="line">        job.setJarByClass(InvertedIndexHbase.class);</div><div class="line">        job.setMapperClass(Map.class);</div><div class="line">        job.setCombinerClass(InvertedIndexCombiner.class);</div><div class="line">        job.setReducerClass(Reduce.class);</div><div class="line"><span class="comment">//        TableMapReduceUtil.initTableReducerJob(tablename, Reduce.class, job);</span></div><div class="line">        job.setOutputKeyClass(Text.class);</div><div class="line">        job.setOutputValueClass(Text.class);</div><div class="line">        job.setOutputFormatClass(TableOutputFormat.class);</div><div class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">      &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后在Hadoop执行操作. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ hdfs dfs -mkdir /user</div><div class="line">$ hdfs dfs -mkdir /user/input</div><div class="line">$ hdfs dfs -put /Users/andrew_liu/Java/Hadoop/wuxia_novels/*  /user/input</div><div class="line">$ hadoop jar WorkSpace/InvertedIndexHbase.jar InvertedIndexHbase  /user/input output1</div></pre></td></tr></table></figure>
<p>执行成功结束后, 打开HBase Shell的操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hbase shell</div><div class="line">&gt; scan &apos;Wuxia&apos;</div></pre></td></tr></table></figure>
<p>#HBase中数据写入本地文件</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.io.FileWriter;</div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.io.FileWriter;</div><div class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</div><div class="line"><span class="keyword">import</span> java.io.FileOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.PrintWriter;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.KeyValue;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HTable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Result;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HBaseAdmin;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Scan;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.ResultScanner;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Hbase2Local</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> Configuration conf = HBaseConfiguration.create();</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getResultScan</span><span class="params">(String tableName, String filePath)</span> <span class="keyword">throws</span> IOException </span>&#123;</div><div class="line">        Scan scan = <span class="keyword">new</span> Scan();</div><div class="line">        ResultScanner rs = <span class="keyword">null</span>;</div><div class="line">        HTable table =  <span class="keyword">new</span> HTable(conf, Bytes.toBytes(tableName));</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            rs = table.getScanner(scan);</div><div class="line">            FileWriter fos = <span class="keyword">new</span> FileWriter(filePath, <span class="keyword">true</span>);</div><div class="line">            <span class="keyword">for</span> (Result r : rs) &#123;</div><div class="line"><span class="comment">//              System.out.println("获得rowkey: " + new String(r.getRow()));</span></div><div class="line">                <span class="keyword">for</span> (KeyValue kv : r.raw()) &#123;</div><div class="line"><span class="comment">//                  System.out.println("列: " + new String(kv.getFamily()) + "  值: " + new String(kv.getValue()));</span></div><div class="line">                    String s = <span class="keyword">new</span> String(r.getRow() + <span class="string">"\t"</span> + kv.getValue() + <span class="string">"\n"</span>);</div><div class="line">                    fos.write(s);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            fos.close();</div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            <span class="comment">// <span class="doctag">TODO:</span> handle exception</span></div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        rs.close();</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        String tableName = <span class="string">"Wuxia"</span>;</div><div class="line">        String filePath = <span class="string">"/Users/andrew_liu/Java/WorkSpace/Hbaes2Local/bin/Wuxia"</span>;</div><div class="line">        getResultScan(tableName, filePath);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>#Hive实践</p>
<p>将本地数据导入Hive</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">hive&gt; create table Wuxia(word string, count double) row format delimited fields terminated by &apos;\t&apos; stored as textfile;</div><div class="line">Time taken: 0.049 seconds</div><div class="line">hive&gt; load data local inpath &apos;/Users/andrew_liu/Downloads/Wuxia.txt&apos; into table Wuxia;</div><div class="line">Loading data to table default.wuxia</div><div class="line">Table default.wuxia stats: [numFiles=1, totalSize=2065188]</div><div class="line">OK</div><div class="line">Time taken: 0.217 seconds</div></pre></td></tr></table></figure>
<p>输出出现次数大于300的词语</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from Wuxia order by count desc limit 100;</div></pre></td></tr></table></figure>
</div></article></div></main><footer><div class="paginator"><a href="/2015/05/10/最大流-最小割基本概念及算法实现/" class="prev">上一篇</a><a href="/2015/04/25/Mac下安装Hive及使用/" class="next">下一篇</a></div><div class="copyright"><p>© 2014 - 2017 <a href="http://andrewliu.in">Andrew Liu</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-58158116-2",'auto');ga('send','pageview');</script></body></html>
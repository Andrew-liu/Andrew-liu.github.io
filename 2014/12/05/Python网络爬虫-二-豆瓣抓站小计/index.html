<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Python爬虫(二)--豆瓣抓站小计 · Snow Memory | Andrew Liu</title><meta name="description" content="Python爬虫(二)--豆瓣抓站小计 - Andrew Liu"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://andrewliu.in/atom.xml" title="Snow Memory | Andrew Liu"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/dinosaurliu" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/Andrew-liu" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/about" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Python爬虫(二)--豆瓣抓站小计</h1><div class="post-info">Dec 5, 2014</div><div class="post-content"><hr>
<p>#1. 豆瓣抓站流程</p>
<ol>
<li>分析url特征(<code>菜鸟阶段</code>)</li>
<li>对需要抓取的数据设计正则表达式</li>
<li>处理HTML中一些特征字符,换行符等</li>
</ol>
<blockquote>
<p>注意异常的处理和字符编码的处理</p>
</blockquote>
<p>#2. 实现的功能</p>
<p><strong>简单的实现了抓取豆瓣电影Top100的电影名称</strong></p>
<p>#3. 后期工作展望</p>
<ul>
<li>抓取更多的有用数据(如:准确抓取导演, 抓取一个电影评论)</li>
<li>使用多线程爬虫</li>
<li>学习第三方的爬虫框架(<code>Scrapy</code>)</li>
<li>深入理解HTML编码和文本处理</li>
</ul>
<a id="more"></a>
<p>#4. 输出结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Top1 肖申克的救赎</div><div class="line">Top2 这个杀手不太冷</div><div class="line">Top3 阿甘正传</div><div class="line">Top4 霸王别姬</div><div class="line">Top5 美丽人生</div><div class="line">...</div><div class="line">Top96 菊次郎的夏天</div><div class="line">Top97 驯龙高手</div><div class="line">Top98 真爱至上</div><div class="line">Top99 致命ID</div><div class="line">Top100 超脱</div></pre></td></tr></table></figure>
<p>#5. 豆瓣抓站源代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python2</span></div><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"><span class="string">"""</span></div><div class="line">一个简单的Python爬虫, 用于抓取豆瓣电影Top前100的电影的名称</div><div class="line"></div><div class="line">Anthor: Andrew Liu</div><div class="line">Version: 0.0.1</div><div class="line">Date: 2014-12-04</div><div class="line">Language: Python2.7.8</div><div class="line">Editor: Sublime Text2</div><div class="line">Operate: 具体操作请看README.md介绍</div><div class="line">"""</div><div class="line"><span class="keyword">import</span> string</div><div class="line"><span class="keyword">import</span> re</div><div class="line"><span class="keyword">import</span> urllib2</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouBanSpider</span><span class="params">(object)</span> :</span></div><div class="line">    <span class="string">"""类的简要说明</span></div><div class="line"></div><div class="line">    本类主要用于抓取豆瓣前100的电影名称</div><div class="line">    </div><div class="line">    Attributes:</div><div class="line">        page: 用于表示当前所处的抓取页面</div><div class="line">        cur_url: 用于表示当前争取抓取页面的url</div><div class="line">        datas: 存储处理好的抓取到的电影名称</div><div class="line">        _top_num: 用于记录当前的top号码</div><div class="line">    """</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span> :</span></div><div class="line">        self.page = <span class="number">1</span></div><div class="line">        self.cur_url = <span class="string">"http://movie.douban.com/top250?start=&#123;page&#125;&amp;filter=&amp;type="</span></div><div class="line">        self.datas = []</div><div class="line">        self._top_num = <span class="number">1</span></div><div class="line">        <span class="keyword">print</span> <span class="string">"豆瓣电影爬虫准备就绪, 准备爬取数据..."</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_page</span><span class="params">(self, cur_page)</span> :</span></div><div class="line">        <span class="string">"""</span></div><div class="line"></div><div class="line">        根据当前页码爬取网页HTML</div><div class="line"></div><div class="line">        Args: </div><div class="line">            cur_page: 表示当前所抓取的网站页码</div><div class="line"></div><div class="line">        Returns:</div><div class="line">            返回抓取到整个页面的HTML(unicode编码)</div><div class="line"></div><div class="line">        Raises:</div><div class="line">            URLError:url引发的异常</div><div class="line">        """</div><div class="line">        url = self.cur_url</div><div class="line">        <span class="keyword">try</span> :</div><div class="line">            my_page = urllib2.urlopen(url.format(page = (cur_page - <span class="number">1</span>) * <span class="number">25</span>)).read().decode(<span class="string">"utf-8"</span>)</div><div class="line">        <span class="keyword">except</span> urllib2.URLError, e :</div><div class="line">            <span class="keyword">if</span> hasattr(e, <span class="string">"code"</span>):</div><div class="line">                <span class="keyword">print</span> <span class="string">"The server couldn't fulfill the request."</span></div><div class="line">                <span class="keyword">print</span> <span class="string">"Error code: %s"</span> % e.code</div><div class="line">            <span class="keyword">elif</span> hasattr(e, <span class="string">"reason"</span>):</div><div class="line">                <span class="keyword">print</span> <span class="string">"We failed to reach a server. Please check your url and read the Reason"</span></div><div class="line">                <span class="keyword">print</span> <span class="string">"Reason: %s"</span> % e.reason</div><div class="line">        <span class="keyword">return</span> my_page</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_title</span><span class="params">(self, my_page)</span> :</span></div><div class="line">        <span class="string">"""</span></div><div class="line"></div><div class="line">        通过返回的整个网页HTML, 正则匹配前100的电影名称</div><div class="line"></div><div class="line">        </div><div class="line">        Args:</div><div class="line">            my_page: 传入页面的HTML文本用于正则匹配</div><div class="line">        """</div><div class="line">        temp_data = []</div><div class="line">        movie_items = re.findall(<span class="string">r'&lt;span.*?class="title"&gt;(.*?)&lt;/span&gt;'</span>, my_page, re.S)</div><div class="line">        <span class="keyword">for</span> index, item <span class="keyword">in</span> enumerate(movie_items) :</div><div class="line">            <span class="keyword">if</span> item.find(<span class="string">"&amp;nbsp"</span>) == <span class="number">-1</span> :</div><div class="line">                temp_data.append(<span class="string">"Top"</span> + str(self._top_num) + <span class="string">" "</span> + item)</div><div class="line">                self._top_num += <span class="number">1</span></div><div class="line">        self.datas.extend(temp_data)</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(self)</span> :</span></div><div class="line">        <span class="string">"""</span></div><div class="line"></div><div class="line">        爬虫入口, 并控制爬虫抓取页面的范围</div><div class="line">        """</div><div class="line">        <span class="keyword">while</span> self.page &lt;= <span class="number">4</span> :</div><div class="line">            my_page = self.get_page(self.page)</div><div class="line">            self.find_title(my_page)</div><div class="line">            self.page += <span class="number">1</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span> :</span></div><div class="line">    <span class="keyword">print</span> <span class="string">"""</span></div><div class="line">        ###############################</div><div class="line">            一个简单的豆瓣电影前100爬虫</div><div class="line">            Author: Andrew_liu</div><div class="line">            Version: 0.0.1</div><div class="line">            Date: 2014-12-04</div><div class="line">        ###############################</div><div class="line">    """</div><div class="line">    my_spider = DouBanSpider()</div><div class="line">    my_spider.start_spider()</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> my_spider.datas :</div><div class="line">        <span class="keyword">print</span> item</div><div class="line">    <span class="keyword">print</span> <span class="string">"豆瓣爬虫爬取结束..."</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<p>#6. 参考链接</p>
<p><a href="http://andrewliu.tk/2014/11/28/Python%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/" target="_blank" rel="external">个人使用的Python编码规范</a><br><a href="http://andrewliu.tk/2014/10/26/2014-10-26-Python%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" target="_blank" rel="external">python正则表达式小计</a></p>
</div></article></div></main><footer><div class="paginator"><a href="/2014/12/06/IOS之控制器数据传递和代理总结/" class="prev">PREV</a><a href="/2014/12/05/Python网络爬虫/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'snow-memory';
var disqus_identifier = '2014/12/05/Python网络爬虫-二-豆瓣抓站小计/';
var disqus_title = 'Python爬虫(二)--豆瓣抓站小计';
var disqus_url = 'http://andrewliu.in/2014/12/05/Python网络爬虫-二-豆瓣抓站小计/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//snow-memory.disqus.com/count.js" async></script><div class="copyright"><p>© 2014 - 2017 <a href="http://andrewliu.in">Andrew Liu</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-58158116-2",'auto');ga('send','pageview');</script></body></html>